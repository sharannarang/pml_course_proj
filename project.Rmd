---
title: "Predict Exercise grades using Machine Learning"
output: html_document
---

## Reading the data
```{r Packages, echo=FALSE, results='hide', warning=FALSE,message=FALSE}
library(caret)
library(ggplot2)
```

Initially, the training data is loaded into R. The read.csv function is used to load the training data into a data frame.

```{r Loading the data, echo=FALSE, cache=TRUE}
pml.data.train <- read.csv("pml-training.csv")
```

Using the caret, the training dataset is then split into a training and test dataset using the createDataPartition function. The data is randomly sampled with 60% of the data belonging to the training dataset. 

```{r split train, echo=FALSE, cache=TRUE}
inTrain <- createDataPartition(y=pml.data.train$classe, p=0.6, list=FALSE)
pml.train <- pml.data.train[inTrain,]
pml.test <- pml.data.train[-inTrain,]
```

## Cleaning the data

Looking at the columns in the training data set, it is noticible that many of the features have a large number of 'NA' fields. In order to build a model, all the features with large proportion of NA values are removed. Any feature more than 95% NA values are eliminated from the dataset. 

```{r remove NA, echo=FALSE, cache=TRUE}
temp <- apply(pml.train, 2, is.na)
temp <- apply(temp, 2, sum)
temp <- temp/nrow(pml.train)
non.na.cols <- temp < 0.95
pml.train.subset <- pml.train[,non.na.cols]
```

After removing the features with a high proportion of NAs, it is noticible that several of the remaining coloumns have a large number of blank entries. In order to check if these are useful, we use the nearZeroVar function to evaluate the variance of the features. A few of the features have near zero variance. These are also eliminated from the training data.

```{r nzv, echo=FALSE,cache=TRUE}
nzv <- nearZeroVar(pml.train.subset, saveMetrics = TRUE)
pml.train.subset <- pml.train.subset[,!nzv$nzv]
```

Finally, the first few columns of the dataset contain row numbers, user names and time related information. These features are not useful in building a predictive model and are eliminated from the datatset. 

```{r elminate time data, echo=FALSE, cache=TRUE}
non.useful.cols <- c(1:6)
pml.train.subset <- pml.train.subset[,-non.useful.cols]
```

As a result, we are left with a training dataset of `r ncol(pml.train.subset)` features. The same transformations are also applied to the testing subset of train dataset.

```{r test data, echo=FALSE, cache=TRUE}
pml.test.subset <- pml.test[,non.na.cols]
pml.test.subset <- pml.test.subset[,!nzv$nzv]
pml.test.subset <- pml.test.subset[,-non.useful.cols]
```

## Pre-processing the training data
In order to explore the features in the training data set, we perform a random forest cross-validation to get an estimate of the number of features that would be required in building a model.

```{r rfcv, echo=FALSE, cache=TRUE}
cv <- rfcv(pml.train.subset[,-53],pml.train.subset[,53], cv.fold = 5, step=0.7)
```
```{r rfcv fig, echo=FALSE}
qplot(cv$error,cv$n.var,size=I(3.5)) + ggtitle("Random Forest Cross Validation for feature selection") + xlab("Error Rate") + ylab("Number of Variables")
```

Now, we use principle componenet analysis to shrink the feature space. The first step in pre-processing involves running a priciple component analysis and generating only 2 principle components.

```{r basic_pca, echo=FALSE,cache=FALSE}
prComp <- preProcess(pml.train.subset[,-53], method="pca", pcaComp = 2)
trainPC <- predict(prComp, pml.train.subset[,-53])
ggplot(trainPC, aes(PC1, PC2))+geom_point(aes(color=pml.train.subset$classe)) + ggtitle("Principle Component Analysis with two components") + scale_color_discrete(name="Classe")
```

From the figure, we can see some segregation among the different classes even with just two components. 

For the final model, we run principle component analysis on the training data with a threshold of 90%.

```{r final_pca, echo=FALSE, cache=TRUE}
prComp.final <- preProcess(pml.train.subset[,-53], method="pca", thresh=0.90)
trainPC.final <- predict(prComp.final, pml.train.subset[,-53])
```

A total of `r prComp.final$numComp` components are required to capture 90% variance from all the features. From the preprocessed object, a new set of features are created for the training dataset.

## Build prediction model

To build a prediction model, we use the random forest algorithm. In order to perform re-sampling, a bootstrap is used with replacement. Bootstrapping is performed 25 times to obtain the optimum prediction. To enable faster processing, the doParallel package is used. 


```{r paralled processing model build, echo=FALSE, message=FALSE, cache=TRUE}
library(doParallel)
cl <- makeCluster(detectCores())
registerDoParallel(cl)
rf.fit <- train(pml.train.subset$classe ~ ., data = trainPC.final, method="rf")
```


## Model Analysis

In order to estimate the insample error rate, the model is used to predict the training data. 
```{r in sample error, echo=TRUE}
cf.train <- confusionMatrix(predict(rf.fit,trainPC.final), pml.train.subset$classe)
cf.train$overall["Accuracy"]
```

Therefore, we observe that the model has 100% accuracy on the training data set. 

The plot below shows the how each principle component impacts the GINI Index error rate. Clearly, all of the priniciple components contribute to the reduction in Gini index.

```{r Variable imporatnce, echo=FALSE}
varImpPlot(rf.fit$finalModel, main="Variable Importance", pch=20, color="blue")
```

## Out of Sample Error

In order to estimate the out of sample error rate, the model is used to predict the testing data that was obtained by splitting the original training dataset. To obtain the principle components for the testng data, the preprocess object from the training data is used. 

```{r testing pca, echo=FALSE, cache=TRUE}
testPC.final <- predict(prComp.final, pml.test.subset[,-53])
cf.test <- confusionMatrix(pml.test.subset$classe, predict(rf.fit, testPC.final))
```

